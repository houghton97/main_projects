{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b133f0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T20:55:22.065142Z",
     "start_time": "2022-03-19T20:55:22.048145Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pulzara\\AppData\\Local\\Temp\\ipykernel_14180\\3814626351.py:2: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/21971449/how-do-i-increase-the-cell-width-of-the-jupyter-ipython-notebook-in-my-browser\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3360f1c",
   "metadata": {},
   "source": [
    "# Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7f131b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T22:36:17.056228Z",
     "start_time": "2022-03-19T22:36:15.031723Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import statsmodels\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from fbprophet import Prophet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.getLogger('fbprophet').setLevel(logging.WARNING)\n",
    "\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23e5da1",
   "metadata": {},
   "source": [
    "# Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d11e67bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T22:36:30.164718Z",
     "start_time": "2022-03-19T22:36:18.671542Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_table('../data/Modelar_UH2022.txt', delimiter = '|', encoding = \"UTF-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079ae168",
   "metadata": {},
   "source": [
    "# Transformaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcedbf5",
   "metadata": {},
   "source": [
    "## Funciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91410b4c",
   "metadata": {},
   "source": [
    "*La funcion ***ID*** devuelve un dataframe con los valores correspondientes de un contador especifico.* \n",
    "\n",
    "* *Se organizan de manera ascendente por una columna especifica (SAMPLETIME)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9e46e01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T22:37:34.332132Z",
     "start_time": "2022-03-19T22:37:34.319104Z"
    }
   },
   "outputs": [],
   "source": [
    "def id(data, i, sort_value_column):\n",
    "    \"\"\"\n",
    "    Esta funcion obtiene un numero de id de contador en especifico.\n",
    "    Realiza un sort values\n",
    "    \"\"\"\n",
    "    data = data[data.ID == i]\n",
    "    data = data.sort_values(by= sort_value_column, ascending=True)\n",
    "    data1 = data.reset_index(drop = True)  \n",
    "\n",
    "    return data1 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8be2cf9",
   "metadata": {},
   "source": [
    "La funcion ***hour*** cambia el formato de las fechas, pasando segundos y minutos a el valor cero. <br>\n",
    "La salida de la columna viene dada por: \n",
    "* year-month-day hour:00:00 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ddc09700",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T22:37:34.348127Z",
     "start_time": "2022-03-19T22:37:34.333128Z"
    }
   },
   "outputs": [],
   "source": [
    "def hour(data1, column_name):\n",
    "    \"\"\"\n",
    "    cambia la fecha y lo deja en una hora sin minutos y segundos. \n",
    "    data, \"column_name\"\n",
    "    \"\"\"\n",
    "    data1[column_name] = data1[column_name].str[:-5]\n",
    "    data1[column_name] = data1[column_name] + '00:00'\n",
    "\n",
    "    return data1 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0934bda2",
   "metadata": {},
   "source": [
    "La funcion ***negativo***  reemplaza los valores negativos de la columna DELTAINTEGER Y DELTATHOUSANDTH por cero. <br>\n",
    "* No deben aparecer valores negativos en un contador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b367b855",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T22:37:34.363285Z",
     "start_time": "2022-03-19T22:37:34.349131Z"
    }
   },
   "outputs": [],
   "source": [
    "def negativo(df):\n",
    "\n",
    "    df[\"DELTAINTEGER\"].mask(df[\"DELTAINTEGER\"] < 0, 0, inplace = True)\n",
    "    df[\"DELTATHOUSANDTH\"].mask(df[\"DELTATHOUSANDTH\"] < 0, 0, inplace = True)\n",
    "    return \"True\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bfa31f",
   "metadata": {},
   "source": [
    "La funcion ***deltainteger*** realiza varias operaciones con el fin de obtener la parte entera y decimal de los valores de consumo de agua en una sola columna. \n",
    "* Pasa la variable SAMPLETIME a un pandas Datetime\n",
    "* Reemplaza los valores NaN por cero de todo el dataset\n",
    "* Se cambia el formato de DELTATHOUSANDTH a tipo int despues a tipo str \n",
    "* Se cambia el formato de DELTAINTEGER a tipo str para ser una union con DELTATHOUSANDTH\n",
    "* Se crea una nueva columna que se llama deltainteger\n",
    "* Es necesario establecer deltainteger como una variable tipo float\n",
    "* Elimina las columnas que no se necesitan y se queda con el ID, SAMPLETIME y deltainteger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c31c7698",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T22:37:34.378721Z",
     "start_time": "2022-03-19T22:37:34.365279Z"
    }
   },
   "outputs": [],
   "source": [
    "def deltainteger(df): \n",
    "\n",
    "    \"\"\"\n",
    "    Esta funcion crea una nueva variable deltainteger que es la suma de DELTAINTEGER + DELTATHOUSAND\n",
    "    Cambia a datetime la columna SAMPLETIME\n",
    "    \"\"\"\n",
    "\n",
    "    df[\"SAMPLETIME\"] = pd.to_datetime(df[\"SAMPLETIME\"])\n",
    "    df = df.replace(np.nan,0) \n",
    "    df['DELTATHOUSANDTH'] = df['DELTATHOUSANDTH'].astype(float).astype(int)\n",
    "    df.sort_values(by=\"SAMPLETIME\", inplace=True)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    df['DELTAINTEGER'] = df['DELTAINTEGER'].astype(str)\n",
    "    df['DELTATHOUSANDTH'] = df['DELTATHOUSANDTH'].astype(str)\n",
    "    df['deltainteger'] = df['DELTAINTEGER'] + '.' + df['DELTATHOUSANDTH'] \n",
    "    df['deltainteger'] = df['deltainteger'].astype(float)  \n",
    "    df.drop(df.columns[[2,3,4,5]], axis = 1, inplace =True) \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fe4081",
   "metadata": {},
   "source": [
    "La funcion ***group*** agrupa el dataset por frecuencia diaria, semanal o mensual. <br>\n",
    "Esta acción se realiza por dos variables:\n",
    "\n",
    "* SAMPLETIME\n",
    "* ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "baeea4ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T22:37:34.394013Z",
     "start_time": "2022-03-19T22:37:34.380249Z"
    }
   },
   "outputs": [],
   "source": [
    "def group(data, column_name, frec):\n",
    "\n",
    "    \"\"\"\n",
    "    Esta funcion agrupa por serie de tiempo en dias para obtener la media de deltainteger\n",
    "    \"\"\"\n",
    "    data = data.groupby([pd.Grouper(key=column_name, freq=frec), \"ID\"]).sum()\n",
    "    data = data.reset_index()\n",
    "    data[\"SAMPLETIME\"] = pd.to_datetime(data[\"SAMPLETIME\"]) \n",
    "    data[\"SAMPLETIME\"] = data[\"SAMPLETIME\"].sort_values(ascending=False)\n",
    "    data = data.set_index(column_name)\n",
    "\n",
    "    return data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483a870d",
   "metadata": {},
   "source": [
    "Esta funcion en conjunto permite detectar la cantidad de outliers que se encuentran dentro de una columna del dataframe \n",
    "* Basado en los percentiles 0.25 y 0.75. La funcion ***remove_outliers*** elimina los valores por fuera del rango intercuartilico\n",
    "* La funcion ***replace_outliers*** reemplaza los valores que se encuentran fuera del quantile 0.25 y 0.95 por la media\n",
    "* La funcion outliers usa las funciones anteriores, detectanto la cantidad de outliers en la columna deltainteger. Si la cantidad de outliers esta por debajo del 5% los elimina, sino se queda con los datos originales. Funciona para IDs que no esten vacios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d4c1a3c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T22:42:19.258152Z",
     "start_time": "2022-03-19T22:42:19.240287Z"
    }
   },
   "outputs": [],
   "source": [
    "def valores_iqr(df_in, col_name):\n",
    "        median = df_in[col_name].median()\n",
    "        q1 = df_in[col_name].quantile(0.25) # 25th percentile / 1st quartile\n",
    "        q3 = df_in[col_name].quantile(0.75) # 7th percentile / 3rd quartile\n",
    "        iqr = q3-q1 #Interquartile range\n",
    "        minimum  = q1-1.5*iqr # The minimum value or the |- marker in the box plot\n",
    "        maximum = q3+1.5*iqr # The maximum value or the -| marker in the box plot\n",
    "        return median, q1, q3, iqr, minimum, maximum\n",
    "\n",
    "def texto_iqr(df_in, col_name):\n",
    "    median, q1, q3, iqr, minimum, maximum = valores_iqr(df_in, col_name)\n",
    "    text = f\"median={median:.2f}, q1={q1:.2f}, q3={q3:.2f}, iqr={iqr:.2f}, minimum={minimum:.2f}, maximum={maximum:.2f}\"\n",
    "    return text\n",
    "\n",
    "def remove_outliers(df_in, col_name):\n",
    "    _, _, _, _, minimum, maximum = valores_iqr(df_in, col_name)\n",
    "    df_out = df_in.loc[(df_in[col_name] > minimum) & (df_in[col_name] < maximum)]\n",
    "    return df_out\n",
    "\n",
    "def count_outliers(df_in, col_name):\n",
    "    _, _, _, _, minimum, maximum = valores_iqr(df_in, col_name)\n",
    "    df_outliers = df_in.loc[(df_in[col_name] <= minimum) | (df_in[col_name] >= maximum)]\n",
    "    return df_outliers.shape[0]\n",
    "\n",
    "def replace_outlier(df_in, col_name):\n",
    "    q1 = df_in[col_name].quantile(0.25)\n",
    "    q3 = df_in[col_name].quantile(0.95)\n",
    "    iqr = q3-q1 #Interquartile range\n",
    "    fence_low  = q1-1.5*iqr\n",
    "    fence_high = q3+1.5*iqr\n",
    "    df_out = df_in.copy()\n",
    "    outliers = ~df_out[col_name].between(fence_low, fence_high, inclusive=False)\n",
    "    df_out.loc[outliers, col_name] = df_out.loc[~outliers, col_name].mean()\n",
    "\n",
    "    return df_out\n",
    "\n",
    "def outliers(data):\n",
    "    \n",
    "    \"\"\"\n",
    "    Esta funcion muestra la cantidad de los valores outliers, y reemplaza los outliers por la media de la columna deltainteger\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    for k, v in data.items():\n",
    "        if data.shape[0] > 0:\n",
    "\n",
    "            q1 = v.quantile(0.25)\n",
    "            q3 = v.quantile(0.95) \n",
    "            irq = q3 - q1\n",
    "            v_col = v[(v <= q1 - 1.5 * irq) | (v >= q3 + 1.5 * irq)]\n",
    "            perc = np.shape(v_col)[0] * 100.0 / np.shape(data)[0] \n",
    "            print(\"Columna %s outliers = %.2f%%\" % (k, perc))\n",
    "        else:\n",
    "            perc = 0 \n",
    "            print(\"Columna %s outliers = %.2f%%\" % (k, perc))\n",
    "    if perc <= 5:\n",
    "        data1 = replace_outlier(data, \"deltainteger\")\n",
    "\n",
    "    else:\n",
    "        data1 = data\n",
    "\n",
    "    return data1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234f68dd",
   "metadata": {},
   "source": [
    "La funcion ***is_weekday*** obtiene de la columna de tiempo datetime, si es un dia de la semaan o un fin de semana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "81fef710",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T22:42:24.310698Z",
     "start_time": "2022-03-19T22:42:24.301757Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_weekday(ds):\n",
    "    date = pd.to_datetime(ds)\n",
    "    return (date.weekday() < 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d4e11b",
   "metadata": {},
   "source": [
    "La funcion ***prophe*** realiza todo el el codigo para obtener un modelo basado en la libreria Prophet, ademas de la metrica. <br>\n",
    "***prophe*** consta de varias funciones creadas anteriormente y nuevas transformaciones que son necesarias para el desarrollo del modelo predictivo.\n",
    "\n",
    "* La libreria de prophet requiere dos entradas especiales con los nombres \"y\" , \"ds\". Es necesario renombrar las columna de deltainteger y SAMPLETIME. Ademas, se elimina la columna ID.\n",
    "* Se añaden las columnas de la funcion ***is_weekday*** para detectar en funcion del tiempo si es fin de semana o no. \n",
    "* Algunos IDs no tienen datos suficientes por lo que es necesario identificarlos dentro del programa con una funcion if shape[0] >2.\n",
    "* Se crea un datetime con las fechas especiales de los dias feriados de la comunidad valenciana, los cuales pueden influir en los picos de consumo\n",
    "\n",
    "**1- Prediccion diaria**\n",
    "\n",
    "* Para determinar la diferencia en dias desde la ultima fecha del dataset y la prediccion, se crea la variable delta2.\n",
    "* Se prepara el Prophet añadiendo los holydays y las vacaciones de España.\n",
    "* La funcion ***dimension*** se encarga de seleccionar los 7 dias antes de la ultima fecha del dataset (df1) para posteriormente ser añadido a la prediccion y de esta manera obtener el valor de RMSE, encontrando los nuevos valores predichos seran validado por los valores de test que corresponden a los 7 dias anteriores a la fecha del dataset.<br> En caso de que no hayan 7 datos, la funcion se encarga de añadir los valores que encuentre a la variable future, ya sean 6,5,4,3,2,1 datos de fechas para realizar la prediccion.  \n",
    "* Se realiza la prediccion, añadiendo las columnas de la funcion is_weekday.\n",
    "* Las predicciones con resultado negativo seran reemplazadas por los valores de cero, que me representar un consumo 0 de agua para ese contador en una fecha especifica. \n",
    "* Por ultimo se determina el valor RMSE usando el valor de test (ultimos 7 dias del dataset) y los 7 dias anteriores que predijo el algoritmo (predice 14 dias dependiendo del tamaño de df1). Esto esta sujeto a cambios, cuando no hay mas de 7 datos o 2 datos en df1, la metrica se calculara con los valores que hayan.\n",
    "\n",
    "**2- Prediccion semanal**\n",
    "\n",
    "* Se trabaja sobre el dataset llamado data_week el cual es definido antes de usar la funcion prophe.\n",
    "* Usando la funcion ***group***, se agrupan los valores por semana\n",
    "* La libreria de prophet requiere dos entradas especiales con los nombres \"y\" , \"ds\". Es necesario renombrar las columna nuevamente: deltainteger y SAMPLETIME.\n",
    "* La variable delta3 es la cantidad de semanas que faltan a partir de la ultima fecha de data_week hasta la semana de prediccion requerida\n",
    "* La funcion dimension2 se encarga de determinar si data_week tiene una dimension <2. Y de esta manera por la falta de informacion la prediccion y el valor RMSE sera igual a cero. \n",
    "* Si la funcion dimension2 encuentra un valor mayor a 2 en data_week realizara la prediccion con los datos utilizando las ultimas dos semanas de data_week mas las semanas de la prediccion requeridas (4 semanas para predecir).\n",
    "\n",
    "**3- Score**\n",
    "* La funcion metrica, obtiene el score final definido como Metrica = 0.5*(daily_RMSE) + 0.5*(week_RMSE)\n",
    "* Se guardan los valores en un dataframe.\n",
    "\n",
    "**4- Salida**\n",
    "* La salida de la funcion ***prophe*** da como resultado la concatenacion de los valores predichos para los 7 dias de la semana mas dos valores que corresponden a dos semanas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a63617f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T22:42:24.451681Z",
     "start_time": "2022-03-19T22:42:24.312682Z"
    }
   },
   "outputs": [],
   "source": [
    "def prophe(df, data_week):\n",
    "\n",
    "    \"\"\"\n",
    "    Esta funcion predice los 10 valores pedidos por datathon, 7 dias + 2 semanas\n",
    "    Ademas de las metricas de evaluacion AVERAGE RMSE\n",
    "    \"\"\"\n",
    "    \n",
    "    proph = True\n",
    "    \n",
    "    # i se encarga de guardar el ID que se obtiene al momento de la ejecucion del programa\n",
    "    i = df['ID'].unique()\n",
    "    # Se cambia el orden las columnas \n",
    "    df.reset_index(inplace=True)\n",
    "    df.drop(df.columns[[1]], axis = 1, inplace=True) \n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    df = df[cols]\n",
    "    # Se renombran las columnas como \"y\" , \"ds\" para utilizar prophet\n",
    "    df = df.rename(columns={\"deltainteger\":\"y\", \"SAMPLETIME\": \"ds\"}) \n",
    "    \n",
    "    #Se eliminan los NaN en caso de que quedara alguno.\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Añadimos la condicion de Marcar fin de semana\n",
    "    df['weekday'] = df['ds'].apply(is_weekday)\n",
    "    df['weekend'] = ~df['ds'].apply(is_weekday)\n",
    "    \n",
    "    # Se define una nueva variable df1\n",
    "    df1 = df\n",
    "\n",
    "    # Checkeamos si existen filas sin datos suficientes para realizar la prediccion:\n",
    "    if df.shape[0] >= 2:\n",
    "        proph = True\n",
    "    else:\n",
    "        print(\"AQUI NO HACE EL PROPHET PORQUE NO HAY DATOS\")\n",
    "        proph = False\n",
    "        \n",
    "    ## PRIMERO VAMOS A AGREGAR DENTRO DEL PROPHET LOS DIAS propios FERIADOS\n",
    "    \n",
    "    if proph:\n",
    "        holidays = pd.DataFrame({\n",
    "            'holiday': 'cvalencia',\n",
    "            'ds': pd.to_datetime(['2019-01-01',\n",
    "                                    '2019-03-19',\n",
    "                                    '2019-04-19',\n",
    "                                    '2019-04-22',\n",
    "                                    '2019-05-01',\n",
    "                                    '2019-06-24',\n",
    "                                    '2019-08-15',\n",
    "                                    '2019-10-09',\n",
    "                                    '2019-10-12',\n",
    "                                    '2019-11-01',\n",
    "                                    '2019-12-06',\n",
    "                                    '2019-12-25',\n",
    "                                    '2020-01-01',\n",
    "                                    '2020-02-06',\n",
    "                                    '2020-02-14',\n",
    "                                    ]),\n",
    "            'lower_window': 0,\n",
    "            'upper_window': 1,\n",
    "        })\n",
    "\n",
    "        ## SACAMOS LA PREDICCIÓN DEL DATATHON PRIMERO\n",
    "        print(\"MODELO DATATHON.\")            \n",
    "        \n",
    "        # Encontramos los dias que necesitamos predecir a partir de la ultima fecha que tiene el dataframe hasta el ultimo dia de la prediccion.\n",
    "        \n",
    "        timestamp = pd.Timestamp('2020-02-07')\n",
    "        delta = timestamp - max(df1.ds) \n",
    "        delta2 = delta.days \n",
    "        \n",
    "        # Preparamos el prophet\n",
    "        m = Prophet(interval_width=0.95, daily_seasonality=True, holidays=holidays) \n",
    "        # Añadimos seasonalitys en función de si es finde o no\n",
    "        m.add_seasonality(name='weekday', period=1, fourier_order=3, condition_name='weekday')\n",
    "        m.add_seasonality(name='weekend', period=1, fourier_order=3, condition_name='weekend')\n",
    "        # Añadimos todas las vacaciones de españa como holidays\n",
    "        m.add_country_holidays(country_name='ES')\n",
    "        m.fit(df1) \n",
    "        \n",
    "        ### PREDICCIÓN PARA LOS SIGUIENTES 7 DÍAS\n",
    "        future = m.make_future_dataframe(periods=delta2, freq=\"D\")  \n",
    "        # Nos quedamos con los primeros 7 dias. del 1 al 7.\n",
    "        future = future.iloc[-7:] \n",
    "        future.reset_index(inplace = True, drop = True) \n",
    "        \n",
    "        # Se crea una funcion dimension para primero: determinar si el tamaño de df1 es superior a 7 o menor. En caso de serlo, se seleccionaran los utimos 7 datos de fechas de df1... \n",
    "        # ...y se añaden al dataframe future con los 7 nuevos datos que son los 7 dias de la semana 01/02/2020 - 07/02/2020.  Se forma un nuevo dataframe de 14 filas en total de las fechas a predecir. \n",
    "        # En caso de que solo se encuentren menos de 7 valores, la funcion dimension se encargara de añadir las ultimas 6,5,4,3,2,o 1 fechas que existan para realizar la prediccion. \n",
    "        # Esto se hace con el fin de determinar el valor RMSE y asi obtener los valores test y pred del modelo. Prediciendo los valores de los 7 dias o menos dias anteriores a la fecha de la... \n",
    "        # ... prediccion real.\n",
    "        \n",
    "        def dimension(tt, future): \n",
    "            if int(tt.shape[0]) >=7:\n",
    "                new_row = {'ds': tt[\"ds\"].iloc[-7]} \n",
    "                new_row2 = {'ds': tt[\"ds\"].iloc[-6]} \n",
    "                new_row3 = {'ds': tt[\"ds\"].iloc[-5]} \n",
    "                new_row4 = {'ds': tt[\"ds\"].iloc[-4]} \n",
    "                new_row5 = {'ds': tt[\"ds\"].iloc[-3]} \n",
    "                new_row6 = {'ds': tt[\"ds\"].iloc[-2]} \n",
    "                new_row7 = {'ds': tt[\"ds\"].iloc[-1]} \n",
    "\n",
    "                future = future.append(new_row, ignore_index=True)\n",
    "                future = future.append(new_row2, ignore_index=True)\n",
    "                future = future.append(new_row3, ignore_index=True)\n",
    "                future = future.append(new_row4, ignore_index=True)\n",
    "                future = future.append(new_row5, ignore_index=True)\n",
    "                future = future.append(new_row6, ignore_index=True)\n",
    "                future = future.append(new_row7, ignore_index=True)\n",
    "                future.sort_values(by = \"ds\", inplace=True, ascending=True) \n",
    "                future.reset_index(inplace = True, drop = True)\n",
    "\n",
    "            elif int(tt.shape[0]) ==6:\n",
    "\n",
    "                new_row2 = {'ds': tt[\"ds\"].iloc[-6]} \n",
    "                new_row3 = {'ds': tt[\"ds\"].iloc[-5]} \n",
    "                new_row4 = {'ds': tt[\"ds\"].iloc[-4]} \n",
    "                new_row5 = {'ds': tt[\"ds\"].iloc[-3]} \n",
    "                new_row6 = {'ds': tt[\"ds\"].iloc[-2]} \n",
    "                new_row7 = {'ds': tt[\"ds\"].iloc[-1]} \n",
    "\n",
    "                future = future.append(new_row2, ignore_index=True)\n",
    "                future = future.append(new_row3, ignore_index=True)\n",
    "                future = future.append(new_row4, ignore_index=True)\n",
    "                future = future.append(new_row5, ignore_index=True)\n",
    "                future = future.append(new_row6, ignore_index=True)\n",
    "                future = future.append(new_row7, ignore_index=True)\n",
    "                future.sort_values(by = \"ds\", inplace=True, ascending=True) \n",
    "                future.reset_index(inplace = True, drop = True)\n",
    "\n",
    "            elif int(tt.shape[0]) ==5:\n",
    "\n",
    "                new_row3 = {'ds': tt[\"ds\"].iloc[-5]} \n",
    "                new_row4 = {'ds': tt[\"ds\"].iloc[-4]} \n",
    "                new_row5 = {'ds': tt[\"ds\"].iloc[-3]} \n",
    "                new_row6 = {'ds': tt[\"ds\"].iloc[-2]} \n",
    "                new_row7 = {'ds': tt[\"ds\"].iloc[-1]} \n",
    "\n",
    "                future = future.append(new_row3, ignore_index=True)\n",
    "                future = future.append(new_row4, ignore_index=True)\n",
    "                future = future.append(new_row5, ignore_index=True)\n",
    "                future = future.append(new_row6, ignore_index=True)\n",
    "                future = future.append(new_row7, ignore_index=True)\n",
    "                future.sort_values(by = \"ds\", inplace=True, ascending=True) \n",
    "                future.reset_index(inplace = True, drop = True)\n",
    "\n",
    "            elif int(tt.shape[0]) ==4:\n",
    "\n",
    "\n",
    "                new_row4 = {'ds': tt[\"ds\"].iloc[-4]} \n",
    "                new_row5 = {'ds': tt[\"ds\"].iloc[-3]} \n",
    "                new_row6 = {'ds': tt[\"ds\"].iloc[-2]} \n",
    "                new_row7 = {'ds': tt[\"ds\"].iloc[-1]} \n",
    "\n",
    "\n",
    "                future = future.append(new_row4, ignore_index=True)\n",
    "                future = future.append(new_row5, ignore_index=True)\n",
    "                future = future.append(new_row6, ignore_index=True)\n",
    "                future = future.append(new_row7, ignore_index=True)\n",
    "                future.sort_values(by = \"ds\", inplace=True, ascending=True) \n",
    "                future.reset_index(inplace = True, drop = True)\n",
    "\n",
    "\n",
    "            elif int(tt.shape[0]) ==3:\n",
    "\n",
    "\n",
    "                new_row5 = {'ds': tt[\"ds\"].iloc[-3]} \n",
    "                new_row6 = {'ds': tt[\"ds\"].iloc[-2]} \n",
    "                new_row7 = {'ds': tt[\"ds\"].iloc[-1]} \n",
    "\n",
    "                future = future.append(new_row5, ignore_index=True)\n",
    "                future = future.append(new_row6, ignore_index=True)\n",
    "                future = future.append(new_row7, ignore_index=True)\n",
    "                future.sort_values(by = \"ds\", inplace=True, ascending=True) \n",
    "                future.reset_index(inplace = True, drop = True)\n",
    "\n",
    "            elif int(tt.shape[0]) ==2:\n",
    "\n",
    "                new_row6 = {'ds': tt[\"ds\"].iloc[-2]} \n",
    "                new_row7 = {'ds': tt[\"ds\"].iloc[-1]} \n",
    "\n",
    "                future = future.append(new_row6, ignore_index=True)\n",
    "                future = future.append(new_row7, ignore_index=True)\n",
    "                future.sort_values(by = \"ds\", inplace=True, ascending=True) \n",
    "                future.reset_index(inplace = True, drop = True)\n",
    "\n",
    "            elif int(tt.shape[0]) ==1:\n",
    "\n",
    "                new_row7 = {'ds': tt[\"ds\"].iloc[-1]} \n",
    "\n",
    "                future = future.append(new_row7, ignore_index=True)\n",
    "                future.sort_values(by = \"ds\", inplace=True, ascending=True) \n",
    "                future.reset_index(inplace = True, drop = True)\n",
    "            return future\n",
    "        # Aplicamos la funcion dimension \n",
    "        future = dimension(df1, future)  \n",
    "\n",
    "        # Realizamos la prediccion y añadimos las columnas que me representan los dias o fines de semana\n",
    "        future['weekday'] = future['ds'].apply(is_weekday)\n",
    "        future['weekend'] = ~future['ds'].apply(is_weekday)\n",
    "        forecast = m.predict(future)\n",
    "        \n",
    "        # Creamos una nueva variable para seleccionar unicamente los dos valores de interes que con la fecha \"ds\" y deltainteger \"yhat\".\n",
    "        forecast1 = forecast.copy()    \n",
    "        forecast1 = forecast[[\"ds\",\"yhat\"]] \n",
    "        # Las predicciones negativas seran reemplazadas por los valores de cero.\n",
    "        forecast1[\"yhat\"].mask(forecast1[\"yhat\"] < 0, 0, inplace = True) \n",
    "        # Seleccionamos los ultimos 7 dias de interes \n",
    "        forecast_1 = forecast1.iloc[-7:] \n",
    "        forecast_1.reset_index(inplace = True, drop = True)\n",
    "        # guardamos en una nueva variable los datos para posteriormente ser concatenados con la prediccion semanal.\n",
    "        frames = [forecast_1[[\"ds\",\"yhat\"]]]   \n",
    "        result = pd.concat(frames)\n",
    "        \n",
    "        \n",
    "        # Metrica de evaluacion primer modelo - manual\n",
    "        \n",
    "        def rango(tt, forecast1):\n",
    "            if int(tt.shape[0]) >= 7:\n",
    "                y1 = sqrt(mean_squared_error(tt[['y']].iloc[-7], forecast1[['yhat']].iloc[-14])) \n",
    "                y2 = sqrt(mean_squared_error(tt[['y']].iloc[-6], forecast1[['yhat']].iloc[-13])) \n",
    "                y3 = sqrt(mean_squared_error(tt[['y']].iloc[-5], forecast1[['yhat']].iloc[-12])) \n",
    "                y4 = sqrt(mean_squared_error(tt[['y']].iloc[-4], forecast1[['yhat']].iloc[-11])) \n",
    "                y5 = sqrt(mean_squared_error(tt[['y']].iloc[-3], forecast1[['yhat']].iloc[-10])) \n",
    "                y6 = sqrt(mean_squared_error(tt[['y']].iloc[-2], forecast1[['yhat']].iloc[-9])) \n",
    "                y7 = sqrt(mean_squared_error(tt[['y']].iloc[-1], forecast1[['yhat']].iloc[-8])) \n",
    "\n",
    "                mean = (y1 + y2 + y3 + y4 + y5 + y6 + y7)/7 \n",
    "\n",
    "            elif int(tt.shape[0]) == 6:\n",
    "                y2 = sqrt(mean_squared_error(tt[['y']].iloc[-6], forecast1[['yhat']].iloc[-13])) \n",
    "                y3 = sqrt(mean_squared_error(tt[['y']].iloc[-5], forecast1[['yhat']].iloc[-12])) \n",
    "                y4 = sqrt(mean_squared_error(tt[['y']].iloc[-4], forecast1[['yhat']].iloc[-11])) \n",
    "                y5 = sqrt(mean_squared_error(tt[['y']].iloc[-3], forecast1[['yhat']].iloc[-10])) \n",
    "                y6 = sqrt(mean_squared_error(tt[['y']].iloc[-2], forecast1[['yhat']].iloc[-9])) \n",
    "                y7 = sqrt(mean_squared_error(tt[['y']].iloc[-1], forecast1[['yhat']].iloc[-8])) \n",
    "\n",
    "                mean = (y2 + y3 + y4 + y5 + y6 + y7)/6\n",
    "\n",
    "            elif int(tt.shape[0]) == 5:\n",
    "\n",
    "                y3 = sqrt(mean_squared_error(tt[['y']].iloc[-5], forecast1[['yhat']].iloc[-12])) \n",
    "                y4 = sqrt(mean_squared_error(tt[['y']].iloc[-4], forecast1[['yhat']].iloc[-11])) \n",
    "                y5 = sqrt(mean_squared_error(tt[['y']].iloc[-3], forecast1[['yhat']].iloc[-10])) \n",
    "                y6 = sqrt(mean_squared_error(tt[['y']].iloc[-2], forecast1[['yhat']].iloc[-9])) \n",
    "                y7 = sqrt(mean_squared_error(tt[['y']].iloc[-1], forecast1[['yhat']].iloc[-8])) \n",
    "\n",
    "                mean = (y3 + y4 + y5 + y6 + y7)/5\n",
    "\n",
    "            elif int(tt.shape[0]) == 4:\n",
    "\n",
    "                y4 = sqrt(mean_squared_error(tt[['y']].iloc[-4], forecast1[['yhat']].iloc[-11])) \n",
    "                y5 = sqrt(mean_squared_error(tt[['y']].iloc[-3], forecast1[['yhat']].iloc[-10])) \n",
    "                y6 = sqrt(mean_squared_error(tt[['y']].iloc[-2], forecast1[['yhat']].iloc[-9])) \n",
    "                y7 = sqrt(mean_squared_error(tt[['y']].iloc[-1], forecast1[['yhat']].iloc[-8])) \n",
    "\n",
    "                mean = (y4 + y5 + y6 + y7)/4\n",
    "\n",
    "            elif int(tt.shape[0]) == 3:\n",
    "\n",
    "                y5 = sqrt(mean_squared_error(tt[['y']].iloc[-3], forecast1[['yhat']].iloc[-10])) \n",
    "                y6 = sqrt(mean_squared_error(tt[['y']].iloc[-2], forecast1[['yhat']].iloc[-9])) \n",
    "                y7 = sqrt(mean_squared_error(tt[['y']].iloc[-1], forecast1[['yhat']].iloc[-8])) \n",
    "\n",
    "                mean = (y5 + y6 + y7)/3\n",
    "\n",
    "\n",
    "            elif int(tt.shape[0]) == 2:\n",
    "\n",
    "                y6 = sqrt(mean_squared_error(tt[['y']].iloc[-2], forecast1[['yhat']].iloc[-9])) \n",
    "                y7 = sqrt(mean_squared_error(tt[['y']].iloc[-1], forecast1[['yhat']].iloc[-8])) \n",
    "\n",
    "                mean = (y6 + y7)/2\n",
    "\n",
    "            elif int(tt.shape[0]) == 1:\n",
    "\n",
    "                y7 = sqrt(mean_squared_error(tt[['y']].iloc[-1], forecast1[['yhat']].iloc[-8])) \n",
    "\n",
    "                mean = (y7)/1\n",
    "\n",
    "            return mean \n",
    "        \n",
    "\n",
    "            # Obtenemos el valor de la metrica RMSE de los ultimos X dias del dataset.\n",
    "        d = rango(df1, forecast1) \n",
    "                    \n",
    "        \n",
    "        ## SACAMOS LA PREDICCIÓN DE LAS SIGUIENTES DOS SEMANAS \n",
    "        # trabajamos sobre el dataset data_week\n",
    "            \n",
    "        \n",
    "        # Organizamos el dataset por semanas\n",
    "        data_week = group(data_week, \"SAMPLETIME\", \"1W\")\n",
    "        data_week.reset_index(inplace=True, drop = False)\n",
    "        data_week.drop(data_week.columns[[1]], axis = 1, inplace=True) \n",
    "        # Cambiamos el orden de las columnas para ingresar los valores al MODELO Prophet\n",
    "        cols = data_week.columns.tolist()\n",
    "        cols = cols[-1:] + cols[:-1]\n",
    "        data_week = data_week[cols] \n",
    "        # Renombramos las variables deltainteger: \"y\", SAMPLETIME: \"ds\"\n",
    "        data_week = data_week.rename(columns={\"deltainteger\":\"y\", \"SAMPLETIME\": \"ds\"})  \n",
    "        \n",
    "        # Encontramos los dias que necesitamos predecir a partir de la ultima fecha que tiene el dataframe hasta el ultimo dia de la prediccion, para posterirmente convertirlo en semanas.\n",
    "        timestamp2 = pd.Timestamp('2020-02-14')\n",
    "        delta3 = timestamp2 - max(data_week.ds)   \n",
    "        delta3 = delta3.days \n",
    "        delta3= round(float((delta3%365)/7)) \n",
    "        \n",
    "        #Segundo modelo\n",
    "        \n",
    "        # La funcion dimension2  determina el tamaño de data_week en caso de ser muy pequeño <2 la prediccion y el error RMSE sera 0, por la falta de datos. \n",
    "        def dimension2(tt2,delta3): \n",
    "\n",
    "            if int(tt2.shape[0]) >=2:\n",
    "                m2 = Prophet(interval_width=0.95, daily_seasonality=True, holidays=holidays)    \n",
    "                m2.add_country_holidays(country_name='ES')\n",
    "                m2 = m2.fit(tt2)   \n",
    "                future2 = m2.make_future_dataframe(periods=delta3, freq=\"W\")   \n",
    "\n",
    "                future2 = future2.iloc[-2:] \n",
    "                future2.iloc[-2] = future2.iloc[-2].apply(lambda dt: dt.replace(day=7, month = 2, year = 2020))\n",
    "                future2.iloc[-1] = future2.iloc[-1].apply(lambda dt: dt.replace(day=14, month = 2, year = 2020)) \n",
    "                dw = data_week[-2:][['ds']]\n",
    "                future2 = pd.concat([dw, future2]) \n",
    "                future2.reset_index(inplace=True, drop = True)\n",
    "                forecast2 = m2.predict(future2)\n",
    "\n",
    "                forecast3_ = forecast2[['ds', 'yhat']]\n",
    "                forecast3_[\"yhat\"].mask(forecast3_[\"yhat\"] < 0, 0, inplace = True) \n",
    "                forecast_3_ = forecast3_.iloc[-2:]\n",
    "                forecast_3_.reset_index(inplace = True, drop = True)\n",
    "                forecast_3_ = forecast_3_\n",
    "\n",
    "                # Error RMSE \n",
    "                y1 = sqrt(mean_squared_error(tt2[['y']].iloc[-2], forecast3_[['yhat']].iloc[-4]))\n",
    "                y2 = sqrt(mean_squared_error(tt2[['y']].iloc[-1], forecast3_[['yhat']].iloc[-3]))\n",
    "                week = (y1 + y2)/2 \n",
    "\n",
    "            else: \n",
    "                diccion = {'ds':[0,0], 'yhat': [0,0]}\n",
    "                forecast3_ = pd.DataFrame(diccion)\n",
    "                forecast_3_ = pd.DataFrame(diccion)\n",
    "\n",
    "\n",
    "                week = 0 \n",
    "\n",
    "            return forecast3_, forecast_3_, week \n",
    "        \n",
    "        forecast3, forecast_3, w = dimension2(data_week, delta3)  \n",
    "            \n",
    "            \n",
    "        # Se determina la Metrica final - Score Final\n",
    "        \n",
    "        def metrica(daily, week):\n",
    "            Metrica = 0.5*(daily) + 0.5*(week)\n",
    "            return Metrica\n",
    "\n",
    "        #Juntamos los modelos\n",
    "\n",
    "        frames1 = [result, forecast_3[[\"yhat\"]]]\n",
    "        result1 = pd.concat(frames1)\n",
    "        result1.reset_index(drop=True, inplace=True) \n",
    "        \n",
    "        #creamos una columna llamada ID con su respectivo numero de contador y eliminadmos la variable \"ds\"\n",
    "        result1 = result1.drop(labels = \"ds\", axis = 1)\n",
    "        result1.reset_index(drop=True, inplace=True) \n",
    "        result1['ID'] = ID\n",
    "        result1.set_index('ID', inplace=True) \n",
    "        \n",
    "        # Metricas            \n",
    "        #creamos una variable para guardar el score final\n",
    "        metri = metrica(d,w) \n",
    "        metricas2 = pd.DataFrame(np.array([metri]))\n",
    "        metricas2 = pd.concat([metricas2]) \n",
    "        metricas2 = metricas2.rename(columns={0:\"metrica\"})\n",
    "        metricas2.reset_index(drop = True, inplace = True)\n",
    "        \n",
    "        \n",
    "        return result1, metricas2, proph \n",
    "        \n",
    "    else: \n",
    "        return 0,0, proph  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6b2239",
   "metadata": {},
   "source": [
    "La funcion ***resul*** crea un dataframe a partir de un diccionario, y se obtiene como salida los valores ID,Predicciones o ID, Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7092eed4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T22:42:24.467682Z",
     "start_time": "2022-03-19T22:42:24.452683Z"
    }
   },
   "outputs": [],
   "source": [
    "def resul(dict, ids_list):\n",
    "\n",
    "    resultado = pd.DataFrame.from_dict(dict,orient='index')\n",
    "    return  resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a60c28e",
   "metadata": {},
   "source": [
    "# Programa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "756a4535",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T22:42:45.317974Z",
     "start_time": "2022-03-19T22:42:24.469683Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Columna ID outliers = 100.00%\n",
      "Columna deltainteger outliers = 0.00%\n",
      "MODELO DATATHON.\n",
      "1\n",
      "Columna ID outliers = 100.00%\n",
      "Columna deltainteger outliers = 2.47%\n",
      "MODELO DATATHON.\n"
     ]
    }
   ],
   "source": [
    "final = pd.DataFrame()\n",
    "final2 = pd.DataFrame()\n",
    "ids_list = []\n",
    "dict_result = {}\n",
    "dict_metricas = {}\n",
    "\n",
    "arr_random_ids = list(range(0,2747)) \n",
    "\n",
    "for ID in arr_random_ids:\n",
    "    print(ID)\n",
    "\n",
    "    data1= data.copy()\n",
    "\n",
    "    hour(data1, \"SAMPLETIME\") \n",
    "    \n",
    "\n",
    "    data1 = id(data1, ID, \"SAMPLETIME\")  \n",
    "    \n",
    "    negativo(data1)\n",
    "\n",
    "\n",
    "    data1 = deltainteger(data1)\n",
    "    \n",
    "    # Se crea una condicion en caso de que el tamaño del data1 sea igual a cero. Se añaden las fechas faltantes con un valor de cero para que el programa funcione. \n",
    "    if int(data1.shape[0]) == 0:\n",
    "        dt = pd.date_range(\"2019-02-01\", \"2020-01-31\")\n",
    "        dt = pd.DataFrame(dt) \n",
    "        dt.rename(columns={0: \"SAMPLETIME\"}, inplace=True) \n",
    "        dt[\"deltainteger\"] = 0\n",
    "        dt[\"ID\"] = ID\n",
    "        data1 = dt\n",
    "    else:\n",
    "        data1 = data1\n",
    "        \n",
    "    # Se creauna copia para utilizar data_week en la prediccion semanal\n",
    "    data_week = data1.copy()  \n",
    "\n",
    "    #Se agrupa por dia, ID el dataframe\n",
    "\n",
    "    data1 = group(data1, \"SAMPLETIME\", \"1D\")\n",
    "    \n",
    "    \n",
    "    # funcion para detectar la cantidad de outliers y reemplazar los valores por fuera del cuartil 0.95 para ser reemplazados por la media\n",
    "    \n",
    "    data1 = outliers(data1) \n",
    "    \n",
    "    # Creamos una copia de data1    \n",
    "    data2 = data1.copy()\n",
    "    \n",
    "    #Implemetamos el modelo Prophet con la funcion creada anteriormente prophe\n",
    "    result, metricas2, proph = prophe(data2, data_week)\n",
    "    \n",
    "    # Creamos un dicionario con los valores de la prediccion y las metricas\n",
    "    if proph:\n",
    "        \n",
    "        dict_result[ID] = result['yhat'].to_numpy() \n",
    "        dict_metricas[ID] = metricas2['metrica'].to_numpy()\n",
    "        # Guardamos los valores de los ID\n",
    "        ids_list.append(ID)\n",
    "\n",
    "# GUardamos las variables de salida para las predicciones y las metricas\n",
    "resul(dict_result, ids_list).to_csv('C:/Users/pulzara/Documents/Datathon/predicciones/F.txt', sep = '|', header = False)\n",
    "resul(dict_metricas, ids_list).to_csv('C:/Users/pulzara/Documents/Datathon/predicciones/M.txt', sep = '|', header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e474ca04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
